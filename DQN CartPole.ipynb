{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2f27989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gym\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2188281a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "## Initialize important variables\n",
    "env_name = 'CartPole-v1'\n",
    "bRender = False\n",
    "load_model = False\n",
    "\n",
    "# Learning factors...\n",
    "EPISODES = 200\n",
    "discount_factor = 0.99\n",
    "learning_rate = 0.001\n",
    "epsilon = 1.0\n",
    "epsilon_decay = 0.999\n",
    "epsilon_min = 0.01\n",
    "batch_size = 64\n",
    "train_start = 1000\n",
    "\n",
    "# create replay memory using deque\n",
    "memory = deque(maxlen=2000)\n",
    "\n",
    "# Create gym environment\n",
    "env = gym.make(env_name)\n",
    "\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "\n",
    "print(env.observation_space.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e50aa3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 24)                120       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                600       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 50        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 770\n",
      "Trainable params: 770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 24)                120       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 24)                600       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 50        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 770\n",
      "Trainable params: 770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The following function creates a neural network which is used as an \n",
    "# approximate Q function\n",
    "# Input: state \n",
    "# Output: Q Value of each action\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(24, input_dim=state_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(24, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(action_size, activation='linear', kernel_initializer='he_uniform'))\n",
    "    model.summary()\n",
    "    model.compile(loss='mse', optimizer=Adam(learning_rate=learning_rate))\n",
    "    return model\n",
    "\n",
    "\n",
    "# create main model and target model\n",
    "model = build_model()\n",
    "target_model = build_model()\n",
    "\n",
    "\n",
    "# if needed, one can load saved model\n",
    "# if load_model == True:\n",
    "#     model.load_weights(\"./cartpole_dqn.h5\")\n",
    "    \n",
    "\n",
    "# after some time interval update the target model to be same with model\n",
    "# This is done using the following function\n",
    "def update_target_model():\n",
    "    target_model.set_weights(model.get_weights())\n",
    "    \n",
    "# We call that function in the beginning to make sure model and target_model have the same weights initally\n",
    "update_target_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21f566d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now define the main function of the DQN... please note that this is only a definition, we do not call it yet as \n",
    "# we are going to define some necessary complementary functions afterwards\n",
    "\n",
    "def main():\n",
    "    global epsilon\n",
    "    \n",
    "    # we want to save scores and episodes in lists....\n",
    "    scores, episodes = [], []\n",
    "\n",
    "    # we now play the defined number of episodes\n",
    "    for e in range(EPISODES):\n",
    "        done = False\n",
    "        score = 0\n",
    "        state = env.reset()\n",
    "        print(state)\n",
    "        # we need to reshape state for input to the neural network\n",
    "        # state is of form:    [-0.01989946  0.18291444 -0.00080162 -0.29979175]\n",
    "        # reshape is of form: [[-0.01989946  0.18291444 -0.00080162 -0.29979175]]\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "                \n",
    "        while not done:\n",
    "            if bRender == True:\n",
    "                env.render()\n",
    "\n",
    "            # get action for the current state and go one step in environment\n",
    "            action = get_action(state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            # state is of form:    [-0.01989946  0.18291444 -0.00080162 -0.29979175]\n",
    "            # reshape is of form: [[-0.01989946  0.18291444 -0.00080162 -0.29979175]]\n",
    "            next_state = np.reshape(next_state, [1, state_size])\n",
    "            \n",
    "            # if an action make the episode end, then gives penalty of -100 unless we reached 500 points / steps\n",
    "            if done == True and score != 499:\n",
    "                reward = -100\n",
    "            \n",
    "            # save the sample <s, a, r, s'> to the replay memory\n",
    "            append_sample(state, action, reward, next_state, done)\n",
    "            \n",
    "            # every time step do the training\n",
    "            train_model()\n",
    "            # here reward is 1 per step, so we count score = number of steps game was playes\n",
    "            score += reward\n",
    "            state = next_state\n",
    "\n",
    "            # if current game is over...\n",
    "            if done:\n",
    "                # every episode update the target model to be same with model\n",
    "                update_target_model()\n",
    "\n",
    "                # every episode, plot the play time\n",
    "                score = score if score == 500 else score + 100\n",
    "                scores.append(score)\n",
    "                episodes.append(e)\n",
    "                pylab.plot(episodes, scores, 'b')\n",
    "                #pylab.savefig(\"./save_graph/cartpole_dqn.png\")\n",
    "                print(\"\\r episode:\", e, \"  score:\", score, \"  memory length:\", len(memory), \"  epsilon:\", epsilon)\n",
    "\n",
    "                # if the mean of scores of last 10 episode is bigger than 490\n",
    "                # stop training\n",
    "                if np.mean(scores[-min(10, len(scores)):]) > 490:\n",
    "                    sys.exit()\n",
    "\n",
    "        # save the model every 50 episodes\n",
    "        if e % 50 == 0:\n",
    "            model.save_weights(\"./cartpole_dqn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd77f8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now define all the complementary functions used above...        \n",
    "\n",
    "# get action from model using epsilon-greedy policy\n",
    "def get_action(state):\n",
    "    if np.random.rand() <= epsilon:\n",
    "        return random.randrange(action_size)\n",
    "    else:\n",
    "        # the model predicts a list of the type [[-1.1730378  1.5907776]]\n",
    "        q_value = model.predict(state)\n",
    "        # we return the action which has the higher Q value\n",
    "        return np.argmax(q_value[0])\n",
    "\n",
    "    \n",
    "# save sample <s,a,r,s'> to the replay memory\n",
    "def append_sample(state, action, reward, next_state, done):\n",
    "    memory.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    global epsilon\n",
    "    # decay epsilon\n",
    "    if epsilon > epsilon_min:\n",
    "        epsilon *= epsilon_decay\n",
    "        \n",
    "\n",
    "# pick samples randomly from replay memory (with batch_size)\n",
    "def train_model():\n",
    "    \n",
    "    global epsilon\n",
    "    global batch_size\n",
    "    global bNotificationStarted\n",
    "    \n",
    "    # only start training when memory is sufficiently full\n",
    "    if len(memory) < train_start:\n",
    "        return\n",
    "    \n",
    "    else:\n",
    "        if bNotificationStarted == False:\n",
    "            print(\"\\n#############################################################################################\")\n",
    "            print(\"Memory sufficiently full, starting to train...\")\n",
    "            print(\"Please note: up to this point no learning happened at all, just random actions to fill memory\")\n",
    "            print(\"#############################################################################################\" + \"\\n\")\n",
    "            bNotificationStarted = True\n",
    "    \n",
    "    # set batch_size (needed if batch_size > memory)\n",
    "    batch_size = min(batch_size, len(memory))\n",
    "    # sample a random mini_batch from memory\n",
    "    mini_batch = random.sample(memory, batch_size)\n",
    "\n",
    "    # we initialize the input and output as follows:\n",
    "    # [[0. 0. 0. 0.]\n",
    "    # [0. 0. 0. 0.]\n",
    "    # [0. 0. 0. 0.] ... batch_size many entries.\n",
    "    states_list = np.zeros((batch_size, state_size))\n",
    "    next_states_list = np.zeros((batch_size, state_size))\n",
    "    # we also initialize lists for actions, rewards and done\n",
    "    actions_list, rewards_list, done_list = [], [], []\n",
    "\n",
    "    # we go through all the samples in the mini_batch\n",
    "    # and split up the samples into input, action, reward lists...\n",
    "    # [0] state\n",
    "    # [1] action\n",
    "    # [2] reward\n",
    "    # [3] next_state\n",
    "    # [4] done\n",
    "    for i in range(batch_size):\n",
    "        states_list[i] = mini_batch[i][0]\n",
    "        actions_list.append(mini_batch[i][1])\n",
    "        rewards_list.append(mini_batch[i][2])\n",
    "        next_states_list[i] = mini_batch[i][3]\n",
    "        done_list.append(mini_batch[i][4])\n",
    "\n",
    "    # target is the prediction of the model for the states of the mini_batch\n",
    "    # that means for each state the four q values\n",
    "    # target is what the net shall learn (we will adjust it in the next lines)\n",
    "    target = model.predict(states_list)\n",
    "    \n",
    "    # target_val is the prediction of the model for the next_states of the mini_batch\n",
    "    target_val = target_model.predict(next_states_list)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # Q Learning: get maximum Q value at s' from target model\n",
    "        if done_list[i]:\n",
    "            # we only adjust the Q value of the action that was used\n",
    "            target[i][actions_list[i]] = rewards_list[i]\n",
    "        else:\n",
    "            # Technically we do one update of the Bellman equation here\n",
    "            # we only adjust the Q value of the action that was used\n",
    "            # we use the prediction of the neural net for the values of the next_states here\n",
    "            # this has to be its own variable so that we do not overwrite stuff in target back and forth\n",
    "            target[i][actions_list[i]] = rewards_list[i] + discount_factor * (np.amax(target_val[i]))\n",
    "\n",
    "    # train the model\n",
    "    model.fit(states_list, target, batch_size=batch_size, epochs=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9c31a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " episode: 0   score: 18.0   memory length: 19   epsilon: 0.9811700348643991\n",
      " episode: 1   score: 30.0   memory length: 50   epsilon: 0.9512056281970315\n",
      " episode: 2   score: 34.0   memory length: 85   epsilon: 0.9184732224159486\n",
      " episode: 3   score: 14.0   memory length: 100   epsilon: 0.9047921471137096\n",
      " episode: 4   score: 21.0   memory length: 122   epsilon: 0.88509434007808\n",
      " episode: 5   score: 20.0   memory length: 143   epsilon: 0.8666920568517111\n",
      " episode: 6   score: 14.0   memory length: 158   epsilon: 0.8537822855004553\n",
      " episode: 7   score: 15.0   memory length: 174   epsilon: 0.8402237462387894\n",
      " episode: 8   score: 15.0   memory length: 190   epsilon: 0.8268805241487632\n",
      " episode: 9   score: 12.0   memory length: 203   epsilon: 0.8161953381180397\n",
      " episode: 10   score: 22.0   memory length: 226   epsilon: 0.7976279044799526\n",
      " episode: 11   score: 21.0   memory length: 248   epsilon: 0.7802631200940584\n",
      " episode: 12   score: 15.0   memory length: 264   epsilon: 0.7678721062162944\n",
      " episode: 13   score: 24.0   memory length: 289   epsilon: 0.7489039087598284\n",
      " episode: 14   score: 23.0   memory length: 313   epsilon: 0.7311354045730207\n",
      " episode: 15   score: 15.0   memory length: 329   epsilon: 0.7195245662400531\n",
      " episode: 16   score: 8.0   memory length: 338   epsilon: 0.7130746876787832\n",
      " episode: 17   score: 15.0   memory length: 354   epsilon: 0.7017506636113059\n",
      " episode: 18   score: 13.0   memory length: 368   epsilon: 0.6919897588949444\n",
      " episode: 19   score: 14.0   memory length: 383   epsilon: 0.6816822575233553\n",
      " episode: 20   score: 16.0   memory length: 400   epsilon: 0.6701859060067403\n",
      " episode: 21   score: 16.0   memory length: 417   epsilon: 0.6588834367523301\n",
      " episode: 22   score: 11.0   memory length: 429   epsilon: 0.6510201771893979\n",
      " episode: 23   score: 14.0   memory length: 444   epsilon: 0.6413229363226717\n",
      " episode: 24   score: 11.0   memory length: 456   epsilon: 0.6336692476264985\n",
      " episode: 25   score: 8.0   memory length: 465   epsilon: 0.6279889833423202\n",
      " episode: 26   score: 8.0   memory length: 474   epsilon: 0.6223596374236124\n",
      " episode: 27   score: 7.0   memory length: 482   epsilon: 0.6173981515854621\n",
      " episode: 28   score: 36.0   memory length: 519   epsilon: 0.5949608504704863\n",
      " episode: 29   score: 21.0   memory length: 541   epsilon: 0.5820082358133997\n",
      " episode: 30   score: 29.0   memory length: 571   epsilon: 0.5647988152354793\n",
      " episode: 31   score: 8.0   memory length: 580   epsilon: 0.5597359112837013\n",
      " episode: 32   score: 12.0   memory length: 593   epsilon: 0.5525028441531146\n",
      " episode: 33   score: 14.0   memory length: 608   epsilon: 0.54427306365317\n",
      " episode: 34   score: 15.0   memory length: 624   epsilon: 0.5356297035976458\n",
      " episode: 35   score: 9.0   memory length: 634   epsilon: 0.5302974457351142\n",
      " episode: 36   score: 16.0   memory length: 651   epsilon: 0.5213541502668072\n",
      " episode: 37   score: 13.0   memory length: 665   epsilon: 0.5141024461386688\n",
      " episode: 38   score: 12.0   memory length: 678   epsilon: 0.5074590676632879\n",
      " episode: 39   score: 12.0   memory length: 691   epsilon: 0.5009015368198305\n",
      " episode: 40   score: 15.0   memory length: 707   epsilon: 0.4929469408197278\n",
      " episode: 41   score: 10.0   memory length: 718   epsilon: 0.4875515553786555\n",
      " episode: 42   score: 11.0   memory length: 730   epsilon: 0.48173300809637676\n",
      " episode: 43   score: 23.0   memory length: 754   epsilon: 0.4703034042831738\n",
      " episode: 44   score: 8.0   memory length: 763   epsilon: 0.4660875651208925\n",
      " episode: 45   score: 20.0   memory length: 784   epsilon: 0.4563969875256424\n",
      " episode: 46   score: 9.0   memory length: 794   epsilon: 0.45185350084291465\n",
      " episode: 47   score: 22.0   memory length: 817   epsilon: 0.44157439301269474\n",
      " episode: 48   score: 11.0   memory length: 829   epsilon: 0.4363045472783448\n",
      " episode: 49   score: 10.0   memory length: 840   epsilon: 0.43152912216191214\n",
      " episode: 50   score: 13.0   memory length: 854   epsilon: 0.42552682695625954\n",
      " episode: 51   score: 15.0   memory length: 870   epsilon: 0.41876922342177453\n",
      " episode: 52   score: 16.0   memory length: 887   epsilon: 0.41170681546900234\n",
      " episode: 53   score: 9.0   memory length: 897   epsilon: 0.4076082248025454\n",
      " episode: 54   score: 8.0   memory length: 906   epsilon: 0.4039543904876318\n",
      " episode: 55   score: 8.0   memory length: 915   epsilon: 0.40033330944997925\n",
      " episode: 56   score: 9.0   memory length: 925   epsilon: 0.3963479433983767\n",
      " episode: 57   score: 12.0   memory length: 938   epsilon: 0.39122622220115044\n",
      " episode: 58   score: 8.0   memory length: 947   epsilon: 0.3877192375315819\n",
      " episode: 59   score: 10.0   memory length: 958   epsilon: 0.38347558663089293\n",
      " episode: 60   score: 9.0   memory length: 968   epsilon: 0.3796580412293454\n",
      " episode: 61   score: 11.0   memory length: 980   epsilon: 0.3751271188281757\n",
      " episode: 62   score: 16.0   memory length: 997   epsilon: 0.3688007209003024\n",
      "\n",
      "#############################################################################################\n",
      "Memory sufficiently full, starting to train...\n",
      "Please note: up to this point no learning happened at all, just random actions to fill memory\n",
      "#############################################################################################\n",
      "\n",
      " episode: 63   score: 10.0   memory length: 1008   epsilon: 0.36476413627946375\n",
      " episode: 64   score: 7.0   memory length: 1016   epsilon: 0.36185621618376534\n",
      " episode: 65   score: 9.0   memory length: 1026   epsilon: 0.35825389420480874\n",
      " episode: 66   score: 11.0   memory length: 1038   epsilon: 0.35397841359256427\n",
      " episode: 67   score: 9.0   memory length: 1048   epsilon: 0.35045451608208705\n",
      " episode: 68   score: 15.0   memory length: 1064   epsilon: 0.34488910274847373\n",
      " episode: 69   score: 7.0   memory length: 1072   epsilon: 0.3421396275316961\n",
      " episode: 70   score: 9.0   memory length: 1082   epsilon: 0.3387335865546259\n",
      " episode: 71   score: 10.0   memory length: 1093   epsilon: 0.3350260916703695\n",
      " episode: 72   score: 9.0   memory length: 1103   epsilon: 0.33169086679493115\n",
      " episode: 73   score: 9.0   memory length: 1113   epsilon: 0.32838884448265515\n",
      " episode: 74   score: 10.0   memory length: 1124   epsilon: 0.32479457450384985\n",
      " episode: 75   score: 13.0   memory length: 1138   epsilon: 0.32027688886632083\n",
      " episode: 76   score: 13.0   memory length: 1152   epsilon: 0.3158220413582485\n",
      " episode: 77   score: 9.0   memory length: 1162   epsilon: 0.3126779951041253\n",
      " episode: 78   score: 10.0   memory length: 1173   epsilon: 0.30925568295888084\n",
      " episode: 79   score: 8.0   memory length: 1182   epsilon: 0.3064834890782873\n",
      " episode: 80   score: 11.0   memory length: 1194   epsilon: 0.30282584784472627\n",
      " episode: 81   score: 10.0   memory length: 1205   epsilon: 0.2995113690735936\n",
      " episode: 82   score: 8.0   memory length: 1214   epsilon: 0.2968265240399636\n",
      " episode: 83   score: 10.0   memory length: 1225   epsilon: 0.2935777088557856\n",
      " episode: 84   score: 8.0   memory length: 1234   epsilon: 0.2909460536500286\n",
      " episode: 85   score: 9.0   memory length: 1244   epsilon: 0.2880496508334416\n",
      " episode: 86   score: 10.0   memory length: 1255   epsilon: 0.2848968999718006\n",
      " episode: 87   score: 8.0   memory length: 1264   epsilon: 0.2823430602649749\n",
      " episode: 88   score: 9.0   memory length: 1274   epsilon: 0.2795323012780908\n",
      " episode: 89   score: 12.0   memory length: 1287   epsilon: 0.27592010513424353\n",
      " episode: 90   score: 9.0   memory length: 1297   epsilon: 0.27317328743509334\n",
      " episode: 91   score: 10.0   memory length: 1308   epsilon: 0.27018336082054484\n",
      " episode: 92   score: 8.0   memory length: 1317   epsilon: 0.2677614145127563\n",
      " episode: 93   score: 10.0   memory length: 1328   epsilon: 0.26483072173851846\n",
      " episode: 94   score: 9.0   memory length: 1338   epsilon: 0.26219430017947276\n",
      " episode: 95   score: 9.0   memory length: 1348   epsilon: 0.2595841245128649\n",
      " episode: 96   score: 8.0   memory length: 1357   epsilon: 0.25725719064833996\n",
      " episode: 97   score: 9.0   memory length: 1367   epsilon: 0.2546961644985321\n",
      " episode: 98   score: 9.0   memory length: 1377   epsilon: 0.2521606336708316\n",
      " episode: 99   score: 8.0   memory length: 1386   epsilon: 0.24990024460085344\n",
      " episode: 100   score: 13.0   memory length: 1400   epsilon: 0.24642429138466176\n",
      " episode: 101   score: 11.0   memory length: 1412   epsilon: 0.24348340979971822\n",
      " episode: 102   score: 10.0   memory length: 1423   epsilon: 0.24081844378493483\n",
      " episode: 103   score: 16.0   memory length: 1440   epsilon: 0.23675711836406457\n",
      " episode: 104   score: 10.0   memory length: 1451   epsilon: 0.2341657727166659\n",
      " episode: 105   score: 11.0   memory length: 1463   epsilon: 0.23137118698432196\n",
      " episode: 106   score: 11.0   memory length: 1475   epsilon: 0.22860995245153565\n",
      " episode: 107   score: 9.0   memory length: 1485   epsilon: 0.22633411298963688\n",
      " episode: 108   score: 10.0   memory length: 1496   epsilon: 0.2238568488524224\n",
      " episode: 109   score: 7.0   memory length: 1504   epsilon: 0.22207224953304477\n",
      " episode: 110   score: 8.0   memory length: 1513   epsilon: 0.22008157526211472\n",
      " episode: 111   score: 9.0   memory length: 1523   epsilon: 0.217890636816753\n",
      " episode: 112   score: 9.0   memory length: 1533   epsilon: 0.21572150942606796\n",
      " episode: 113   score: 11.0   memory length: 1545   epsilon: 0.21314704158045672\n",
      " episode: 114   score: 25.0   memory length: 1571   epsilon: 0.20767394027814676\n",
      " episode: 115   score: 27.0   memory length: 1599   epsilon: 0.2019368945917472\n",
      " episode: 116   score: 77.0   memory length: 1677   epsilon: 0.18677715459292282\n",
      " episode: 117   score: 50.0   memory length: 1728   epsilon: 0.17748581718674777\n",
      " episode: 118   score: 86.0   memory length: 1815   epsilon: 0.16269010151972138\n",
      " episode: 119   score: 35.0   memory length: 1851   epsilon: 0.15693460054388708\n",
      " episode: 120   score: 63.0   memory length: 1915   epsilon: 0.14720072626817587\n",
      " episode: 121   score: 40.0   memory length: 1956   epsilon: 0.14128464672434274\n",
      " episode: 122   score: 31.0   memory length: 1988   epsilon: 0.13683291949436335\n",
      " episode: 123   score: 28.0   memory length: 2000   epsilon: 0.13291982224058757\n",
      " episode: 124   score: 50.0   memory length: 2000   epsilon: 0.12630764893118168\n",
      " episode: 125   score: 88.0   memory length: 2000   epsilon: 0.11554684815352155\n",
      " episode: 126   score: 51.0   memory length: 2000   epsilon: 0.10968910456830164\n",
      " episode: 127   score: 152.0   memory length: 2000   epsilon: 0.09412027550834177\n",
      " episode: 128   score: 83.0   memory length: 2000   epsilon: 0.0865334862270506\n",
      " episode: 129   score: 63.0   memory length: 2000   epsilon: 0.08116624361354205\n",
      " episode: 130   score: 387.0   memory length: 2000   epsilon: 0.05505349298312672\n",
      " episode: 131   score: 81.0   memory length: 2000   epsilon: 0.05071715848014838\n",
      " episode: 132   score: 170.0   memory length: 2000   epsilon: 0.04274185828881007\n",
      " episode: 133   score: 75.0   memory length: 2000   epsilon: 0.03961234065868409\n",
      " episode: 134   score: 85.0   memory length: 2000   epsilon: 0.03634649129804764\n",
      " episode: 135   score: 87.0   memory length: 2000   epsilon: 0.03328322926552661\n",
      " episode: 136   score: 120.0   memory length: 2000   epsilon: 0.029488286128567263\n",
      " episode: 137   score: 221.0   memory length: 2000   epsilon: 0.02361499826895695\n",
      " episode: 138   score: 111.0   memory length: 2000   epsilon: 0.0211116705177843\n",
      " episode: 139   score: 111.0   memory length: 2000   epsilon: 0.018873710130115927\n",
      " episode: 140   score: 197.0   memory length: 2000   epsilon: 0.015481889002053564\n",
      " episode: 141   score: 198.0   memory length: 2000   epsilon: 0.012686917226876196\n",
      " episode: 142   score: 404.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 143   score: 219.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 144   score: 256.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 145   score: 209.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 146   score: 102.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 147   score: 154.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 148   score: 86.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 149   score: 250.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 150   score: 248.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 151   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 152   score: 164.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 153   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 154   score: 141.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 155   score: 100.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 156   score: 160.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 157   score: 308.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 158   score: 127.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 159   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 160   score: 124.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 161   score: 340.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 162   score: 201.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 163   score: 246.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 164   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 165   score: 156.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 166   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 167   score: 424.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 168   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 169   score: 419.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 170   score: 310.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 171   score: 346.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 172   score: 308.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 173   score: 247.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 174   score: 313.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 175   score: 489.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 176   score: 353.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 177   score: 334.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 178   score: 479.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 179   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 180   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 181   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 182   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 183   score: 477.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 184   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 185   score: 442.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 186   score: 8.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 187   score: 8.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 188   score: 8.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 189   score: 298.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 190   score: 137.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 191   score: 150.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 192   score: 125.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 193   score: 398.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 194   score: 372.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 195   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 196   score: 366.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 197   score: 371.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 198   score: 439.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      " episode: 199   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "\n",
      "\n",
      "Laufzeit: 4324.592s\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAh/UlEQVR4nO3de5QV1Z0v8O8P5CnyEmibh9OoXJfgTCJ0GJfRjCMYhGsEY8xgXmRiJHGRjM5kJmp0rrpGMiaZIZnMjE5QcRjjSPA6KslEIgtNsu4aozQ+QCRIC4odniLK04aG3/2jaufUqa46p+rUY9c5/f2s1avO2adq16+rT//OPruq9hZVBRERNZZetgMgIqL0MbkTETUgJnciogbE5E5E1ICY3ImIGtBJtgMAgBEjRmhLS4vtMIiI6sratWvfUdWRQa8VIrm3tLSgra3NdhhERHVFRN4Ke43dMkREDYjJnYioATG5ExE1ICZ3IqIGxORORNSAIiV3EXlTRNaLyMsi0uaWDReRVSKy2V0O86x/i4i0i8gmEZmRVfBERBQsTsv9T1X1w6ra6j6/GcBqVZ0AYLX7HCIyEcBcAJMAXAbgHhHpnWLMRERURZJumdkAlrqPlwKY4ylfpqqdqroVQDuAqQn2Q0R15pprABHg618HVq50Hl94Yfj6x48764gEvz56tPPavn3AxRc7j597DrjtNufx979fe6ynnVbat/fnJPcuoF69gD59aq8fAFpagBtu6F7+wx8Cjz6arO4wEmU8dxHZCmAfAAXwI1VdLCLvqepQzzr7VHWYiPwLgN+o6o/d8gcAPKWq/9dX53wA8wHg9NNPn/LWW6HX4hNRnQlL0mHp5lOfAh57LHydsPqi1F1NpbpVS68nmfpCxPmAOHq0vPyss4Dzzwd+/ONa65W1nt6UMlHvUP2oqm4XkVEAVonIbyvtL6Cs22FR1cUAFgNAa2srZwwh6sE2bLAdQXnyNgl9yZLk9R475ixPnOj+2nvvAUOHJt9HkEjdMqq63V3uBvA4nG6WXSLSDADucre7egeAcZ7NxwLYnlbARNR49u61HUGw665LXseWLcHlqpaTu4icLCKnmMcAPg7gVQArAMxzV5sH4En38QoAc0Wkn4iMBzABwAtpB05EjaOzM/t9vP8+sGtXedmf/VnlbYJa23GZ5O7v1jl0yDnXkFVyj9It0wTgcXG+p5wE4D9VdaWIrAGwXESuBbANwNUAoKobRGQ5gNcAdAFYoKrHM4meiBpCHsndJFFvkl2+PHjdQYOAgwfLy7ZtA04/Pf5+d+zovl/AabV740pb1eSuqlsAfCigfC+AaSHbLASwMHF0RNQjmH5pW04+ufz5E08A06eXl33rW7Wd+DTJ3S/r5M47VInIujS6P6LaubN72dat5c+nBTRbf/3r2va32z0b6W+579vnLJnciYhS8M//3L1sZOB0F+VMko7LJHE/ttyJiFK0alVt2/mvUY+KyZ2IKAcdHbVtV+tNTAcOBJczuRMRpej9953lM89UXm/LFmDMGOCMM5Ltz3/VjWGS+5AhyeoPw+RORD2K6V55+OHK640f77TyP/GJZPs7fDi4/L33nKt0ko5bE4bJnYh6lK4uZ7luXbT177wz2f4++CC4PMu7UwEmdyLqoaL2vSftNgm7QYvJnYgoA4cO5bOfsBu0mNyJiDJw5Eg++2FyJyJKoNoJUr/jOY14Zfr4/Y+Z3ImIIrjjjnjrJ5l8Iw7vh4i3n5/JnYgogqJO5uZN7t4RIpnciYgiyGNkSXMDVBzebwhmfJqDB53B0pjciYgK4O//Pv423hEvzWQhWQ89ADC5ExFF9vjj8bfxttzffddZMrkTEWXMTIYdRS2DjnmTuxkhksmdiChjvXtXX8d8AIQNJRDV/v3Ocs8eZ8nkTkSUkX79qq/TK0Gm9LbcTYv96aedZS0naKNicieiujZiRPV1Xnwx/LVTTkkvlmrM8L979zrL0aOz2xeTOxHVtc99rvo6P/lJ+GtjxlTf3nTLJL3xyYxnY1rsUfZdKyZ3Iqpr3/9+9XVeein8tbPPrr59nJOulZjkbvreBw9Op94gTO5E1PC2bAl/7aqrqm9v+tyTttzNCdkDB9L7wAjD5E5EDc9cXx7kk5+svn1aidgk90OHgJNOSqfOMEzuRNTwkg7vm1ZyN1P8HTnC5E5ElFjScWeiXAsfhUnuH3wQ7RLMJJjciaguqUbvA086dnuS69yBUsvffMgcPQr075+szmqY3ImIqkjacjcfDmayjq4uYODAZHVW3We21RMR1b+0k/vx48DJJyers+o+s62eiKj+1dot8847ztJ8OBw/7gwBrJr9nbFM7kREVfTpU9t2W7c6S5PcT5wojQyZ5Q1MQIzkLiK9ReQlEfmZ+3y4iKwSkc3ucphn3VtEpF1ENonIjCwCJ6LsqTonAfOab7Soak3u27Y5S29y/93vnMdZjggJxGu53wBgo+f5zQBWq+oEAKvd5xCRiQDmApgE4DIA94hIShcSEVGebrgB6Ns3+dUi9a7WPvedO52l+XA4caI0j+rw4cnjqiTSn0xExgL43wDu9xTPBrDUfbwUwBxP+TJV7VTVrQDaAUxNJVoiytWSJbYjiOeRR7Kpt2/f2rYzidwkd9VSwj/11ORxVRL18/gHAL4JwDMbIJpUdQcAuMtRbvkYAG971utwy8qIyHwRaRORtj1m5HoiKhQz0FW9WLQom3oHDIi3/vHjTmv/wQed5+aGJdXSJNkjR6YXX5CqyV1ELgewW1XXRqwz6Ebdbj12qrpYVVtVtXVk1r8lEdWt9vbo677+ejYxxL2bdP16pwtm+3bnublhSbV0BU1TU3rxBYkyusFHAVwhIrMA9AcwWER+DGCXiDSr6g4RaQbgfh6hA8A4z/ZjAWxPM2gi6jmefTb6umYyjGpWrowXQ9zkblrnhveGJTNRx2mnxaszrqotd1W9RVXHqmoLnBOlz6jq5wCsADDPXW0egCfdxysAzBWRfiIyHsAEAC+kHjkR9QhxEvGJE9XXAYCHHooXQ9yhAsx0esbAgc4QBKqlSyGbm+PVGVeSc+B3A7hURDYDuNR9DlXdAGA5gNcArASwQFUTjuxARHE88oiTTDo7bUeS3KZN6de5bl289YcMibe+f4hh7w1LeczCBETrlvk9Vf0lgF+6j/cCmBay3kIACxPGRkQ1+sxnnGX//vV/jbpp6abJXMUSVdyhAsxMS8awYaWWu0nuHFuGiHo0f6JMQ9S+eSPuUAH+bpkhQ0ojQx48mM99A0zuRFRoWXQtxR3fPe5QAYcPlz9vaiol98OH0xsfvhImdyIqtKQTbQSJeuLViDtUgP/bRlNTqbV+5EjtwxnEweRORKmqt7taoxg9Ot76/pu/mptLyT2PWZgAJnciStnPf57/PrOejzTufZZmImyjpaXUFZPHLEwAkzsRpWxt1HvZUxT3UsW44l6T7p+Qe8yYUnLv7CzNpZolJnciSpW5vb5WTzwRf5vzzku2z2rGjo23vjkJ3L8/MHOm02fv/XbxR3+UWmihmNyJKFX+K0XieqGG+9lvvz3ZPquJe7WMabkPHOh0U/XpUzqJOmgQ8Mwz6cYXhMmdiFIV90oUv1q6dS68MNp6EjSsYQZMt4v3ksfLL3da77/5TT4xMLkTUaF0dGRXdx6XIAKl5O7tirn/fueyzkmT8omByZ2ICiWLO1KNuMMI1Mpcm5/HzUphmNyJqFAOHMiu7hEjsqvbq6vLWWZ9iWYlTO5EVCgmMWbhD/8wu7q9TMs9r26gIEzuRFQoWQ5TfOut2dXtZU4qs+VOROTKsuU+eXL586yunjG/Qx7DDIRhcieihiISPWlndcLzuDs9EZM7EZEFWSVfk9z79s2m/iiY3ImocEScOzmTiHKzUNxJOKIyfe4DBmRTfxRM7kQUyaJF+e7PP2xuXDNnBpcvX156HHe0x6hMcs9j9McwTO5EFMm999qOIB7/VHfG1VeXHmd1aaSZtzbreVIrYXInokjefDN5HevWJa8jTXPmZFMvu2WIqG6kcYni/fcnryMNprtk1qxs6jct96z69KOweIk9EfU0NibyCOKfTCNtpuWe9SQilbDlTkS5yXLExyJKesVPEkzuRJSbgwdtR5AP03IfPtxeDEzuRJSbrLtDguzYkf8+jbgzOKWJyZ2IcpPloGBhHngg/32aE6p5DTEchMmdiHKTdAq+uJ57DlizJt99etnsluHVMkTUsGbMAEaPtrd/m/tmy52IGtaBA3au0OGlkETUYx0+7AwQlvWEFknHqEmi0EP+ikh/EXlBRF4RkQ0icqdbPlxEVonIZnc5zLPNLSLSLiKbRGRGlr8AEdUnM1m1GR43qcOHgaYmZ4LtXmy2Rmq5dwK4RFU/BODDAC4TkfMB3AxgtapOALDafQ4RmQhgLoBJAC4DcI+IWJwDnIh6ggEDgJ07nVv+zzrLdjT2VU3u6jC3HvRxfxTAbABL3fKlAOa4j2cDWKaqnaq6FUA7gKlpBk1EVMlDD9mOwL5IX15EpLeIvAxgN4BVqvo8gCZV3QEA7nKUu/oYAG97Nu9wy/x1zheRNhFp27NnT4JfgYio3NSA5mQW/d8dHc55g7/92/TrTipSclfV46r6YQBjAUwVkXMrrB40e6EG1LlYVVtVtXVkViPmE1Fd+9nP0qvr7LPTq8u48kpneddd6dedVKzTDqr6HoBfwulL3yUizQDgLne7q3UAGOfZbCyA7UkDJaKeJ83Zn7K4U/X999OvMy1RrpYZKSJD3ccDAEwH8FsAKwDMc1ebB+BJ9/EKAHNFpJ+IjAcwAcALKcdNRD1AmkMEt7amV5dx9Gj6daYlyhWmzQCWule89AKwXFV/JiLPAVguItcC2AbgagBQ1Q0ishzAawC6ACxQ1ZQudiKinqToo0jWdXJX1XUAzgso3wtgWsg2CwEsTBwdEfVoeY9FE9exY7YjCMdL/YmIapTWDVhZYHInIqpRGvPKZoXJnYioRtrtIu/iYHInIqoRW+5ERA2ILXciqjv/8z+2Iyg+Jnciqjtf+5rtCIqvyJdqMrkTUaDXX7cdQTK9e/hA40zuRBTI5gxGaTjzzOz3wZY7EVHOevqY7kzuRNSQgsZ0TxtPqBJRQxBxfmyLG0NW/e9M7kSUm6efth1B9uJOgN0T5wNicidqMAstjce6cmV+rfqTogxW7nHTTdnEUWRM7kQNZtMmO/udOTO/ffXpE2/9G2/MJIxCY3InajDvvGM7guwNGGA7guJjcidqMEUYY3zXrmzrHzw42npxu28aCZM7EcX2/POVXx81Ktv9Rz1BeuxYsa9oyRKTOxHFdv75dvffE69+iYvJnYgykeXYLhMnZld3o2ByJ6JUDR/uLPv1y24f06dnV3ejYHInolR97GPO8uSTs9sHk3t1TO5ElKrbbnOWTU3p1TluXHp1ZWXbNtsRlGNyJ6JUTZniLM85J706V69Or66kwq6+2bAh3ziqYXInokzMmpVeXRMmpFdXUvv3B5dv3JhvHNUwuRP1cFmN9PjFL5YeZ9n/nrewJL51q7M0yT/u4GZpY3InoshqTVj+WZGK1oURx+7dweU7dzrLPXvyi6USJnciiuzo0dq2u+ii8uff+17yWGwJG7vHJPV3380vlkqY3ImoKlXnp9Ybk667rvz5U08lj8mWffuCy99/31malr3tSU2Y3Ikocx/6UPnzsARZie0+bCOsW+bgQWfJbhkiysWttybbfsiQ4PLm5trrPHYs/jZZDmcQx4EDweWHDztLk+QL33IXkXEi8qyIbBSRDSJyg1s+XERWichmdznMs80tItIuIptEZEaWvwARVbZsWbT1rrgiuHzy5OBycwIxL0UZvtckb7/OTmdp+twLn9wBdAH4hqqeA+B8AAtEZCKAmwGsVtUJAFa7z+G+NhfAJACXAbhHRArymUvU80RNwj/9aXD5XXelF0sS/fvbjsBx6FBwuTnZbF4vfHJX1R2q+qL7+ACAjQDGAJgNYKm72lIAc9zHswEsU9VOVd0KoB3A1JTjJqKITHdBrS64IJ04kirKtfJhNzF1dTlL021j+xxBrN2LSAuA8wA8D6BJVXcAzgcAADM8/xgAb3s263DLiKhgfvWr7mWqwIgR+ccSxlxpM2xY5fXy8sEHweVmBizzYWq75R65F0tEBgF4DMCNqrpfwiMPeqHbaAwiMh/AfAA4/fTTo4ZBRCn6whe6lw0eXN6v3NmZ7fC9YfxjuIwbB6xfn38cfqZv3e/ECWdZNydUAUBE+sBJ7A+r6n+5xbtEpNl9vRmAuUCoA4B3DLexALb761TVxaraqqqtIzmtCpEVQSMZehN7nz52EnuQ0aNtR+ColtxNy73w3TLiNNEfALBRVRd5XloBYJ77eB6AJz3lc0Wkn4iMBzABwAvphUxEean1jtQs2J7azzhyJLjcfNMwyd92co/SLfNRAJ8HsF5EXnbLvgXgbgDLReRaANsAXA0AqrpBRJYDeA3OlTYLVLUA87ETUT27+GLbETiOV8lmpk/e9nX5VZO7qv4/BPejA8C0kG0WAliYIC4iojL+wcdsCbsBy7Tczbcd2y133qFKRBRDtbtrTbeM7ZY7kzsRUQzVumVMy932HbVM7kQUy8SJtiOwq1pyNy17JnciqisPPti9bO3a2uqy3XVRi2rJ3dypyuRORIUUNurj1IDBRO69t7Z9nHpqbdvZZK5nD2OSe58+2cdSCZM7UQ8gEn59dpjly6OvGzboWDUzZ9a2nU1Rk3vfvtnHUgmTO1EPMXBgvPUvvDD6urVOUPE3f1PbdjZVS+7mdbbciaju+ceBiWrSpHTjyEO139X0ydseopjJnYgoAjMQGJM7EVEDitotY3vAtYJMXEVEjajW7poiq/Y7meQe9xxH2thyJ6JCsH0Cspqo3TLmdXbLEFHdEklvUgrblw5WEze5Dx6cbTzVMLkTNYA0k6wtUZK7arG7ev7yL0snVE85xW4sTO5Ede6pp2xHkI6hQ21HUFmUlvsPflAaW8b2hN5M7kR1bs4c2xGkY8gQ2xFUFveb0fDh2cQRFZM7UZ1Lcyq8BQvSqyvMsmXB5UWZjCOMmXwjarfQoEHZxRIFkzsR/V6tA4DF8ZWvBJdfdFH2+04ibst95Mhs4oiKyZ2Ifi+Pk5X79weXf/zj2e87ibjJ3XY3E5M7ERXCOefYjqCyKGPPe8dwDxsyOS9M7kRUOLYnlw7ij+nQodLjceOcxO4dCI3dMkRkxXXX2Y4gnO1xWYL4W+67d5ceb9vmXAJ5552lMt7ERESpaWmJvu4DD6S//7RupCriNe/+5L5tW/d1Zs/OJ5YomNyJGshbb0VfN4uTp3G6IirNMTpmTPJY0ubvlnnzTSthRMbkTkSpueCC6Ot++9vhr82YkTyWtPkHNnvnncrr2x4mgcmdiFJz223hr919d/lzM8Ve0Hgxn/lMunGlwZ/c9+4NXu/224Fzz60+7nvWmNyJepDVq6OtV2vf+ZQp4a/ddFP17U2inzixtv1nqdIJVa877gDWr4926WSWmNyJGlTQZBFf/Wq0ba+/Pt1YGoF/1MqDB+3EERWTO1GDOu207mXt7dG2/dd/TTeWRjBgQPnz996zEkZkTO5EDeqP/zjaes8+m20cjcJ/7f2RI3biiIrJnahBfelL0da7+OL4dRexTzxrDZfcRWSJiOwWkVc9ZcNFZJWIbHaXwzyv3SIi7SKySUQKeEETUc8wfXr0dc2JzKgzHT34YO1x1St/t4x3+IEiitJy/3cAl/nKbgawWlUnAFjtPoeITAQwF8Akd5t7RMTyOWMiStvUqbYjyJ9/OAEz41JRpzesmtxV9dcA3vUVzwaw1H28FMAcT/kyVe1U1a0A2gH0wLcBUbH1xOSclH/aPDNJSt0m9xBNqroDANzlKLd8DIC3Pet1uGVEVCBr1tiOoP74J7xOcwasLKR9QjXoMyywB09E5otIm4i07dmzJ+UwiChrUfvnvUw/dZEG2IrKP/lG0btlKgzdU9EuEWlW1R0i0gzA3KvVAWCcZ72xALYHVaCqiwEsBoDW1lbLozAQUa169waOH4+27sCB9sdcqVVTU/lzM7xAUZN7rS33FQDmuY/nAXjSUz5XRPqJyHgAEwC8kCxEIiqyKMMKNILhw8ufF73lHuVSyEcAPAfgbBHpEJFrAdwN4FIR2QzgUvc5VHUDgOUAXgOwEsACVY34mU5EcYhEn7HIf+u8kUYreuHC5HXUA/9wxubYFTW5V+2WUdVrQl6aFrL+QgA95M9NlC6TKKolXTNCYdTk/M1vAnfdVb4Pimf06PLnXV3OsohTAgK8Q5WoLpnEEtXf/V1web32f9vgn0DEHDsmdyIqFNX0WvFdXY3/QeG/icn8vraH9g3D5E5UEH/xF/ntK+1EXNQElyVztUxRf/daL4UkopQEtZ7POiv68LyVnDjBPvasVZoL1ia23IkK6I034m8T1BoPSuxRZ2OiykzLncmdiArhkktsR9BYiprcCxoWUc+wYEF++2r0E555M8fTP857UbDlTmTRPffYjoCSMvccFA2TO1FBifBkaJGx5U5EqaqU8FeuzC8OcvjHeS8KJneigvMPNVvJDHdiy0GDsomFuhs40HYEwXhClajg9u+Ptz5PnOYrzodvnthyJyJKoKjfkpjciRpAURNMTzB0qO0IgjG5E9WpJ58sPf6P/7AXR083alT1dWxgcicqgC9+0Vn+0z9F3+aKK4DDh50Zga68MpOwKIIRI2xHEIzJnagAHnzQOREaNjJkc3Nw+YABxb39vafwz61aFEzuRHVg505nyZuaiufMM21HEIzJnYgogfHjbUcQjMk9J+ZW8nfftR0JFcWjj1Zf5+tfzz4OSoZ3qGbMJM+if2099VTbEVBRfPrT1df54Q9Lj73v7Z/+NP14qLE0RHIvekIniuO++5zlpEnh61x+eT6xUP1qiOReb+rlWwbZ8eUvO1fOvPqq85zDCVAt6j65M0FSPYr7vp08OZs4qHHVfXIPEvUfx8yB6N0ui1b1pz6VXl1BTLz+30eVrb56EHYNu9fataW/Zdi18EReDXv7gzc5ByW4Sy4Bnn229Py887qvM2MG8ItfJI/lsceS1xFF797AoUNAZycwbBjQy/PRzSRfHNXem5Xw70hR1XVy9/+ThLW2Rbr/U3gTOwC89FL37Z5+Oll8NhT1siwiyldDdssE+ZM/KXVfHD0af/tzzy1/XmsXzkUXAVddVV6P18yZTnxjx4bXPX06cPx48PZRJe1+Mtt+4xuV1/vCF2qrv8jS6ra7/vrkdRCFUlXrP1OmTNFalHqVw8u8z4N+/OtMnx5tu2p1xokzys/nP1/b7xd1/SCdncHlH/lI9W3Dfu8o60ZZP6qw3yGq++5z4vnsZ53nSeO8/vr0f0fKT9D/kt140KYhebWuW+7efzO/Cy6IV4+xalXyuESAOXMq7yeuhx7q3lqM23qMs76IM/Gv2ebLXwa+8hWnL3/NmvB6q30juP124CMfqR6XCHDnncC+feH1vv12+TaLFgF79oT/Dt/9LnDggPP4298GvvOd4Bi9rrvOWT78cHic/tjuv7+0H797762+T6I0iCbJOClpbW3Vtra2zOo/ehTo27f0POoJrbAENWsW8N//XX09P+++grbRCucNajV/PrB4cXgsvJTUngL861FM5v+lb99S967Nv6OIrFXV1qDX6rrlHpU3sQOVW/yVmG28iR1wxtQ2r8+eHb2uoOfe8mPHwjtZvP78z8Pr/tGPqu+7Fq2t6b+pa/mb5KWlpfx50nMJRf09KZpaztvlLbPkLiKXicgmEWkXkZuz2k+WvP+Alf4ZBwwovf7EE8kvb+vsdK5ZrzROtzfRL1nSvY6urvIPjLAPBlVnf2H1+5+fOOEsTddMUH3m5+jRyq+buoL2deRI8P7D/ib/8A/O80WLgrcJq8/E4I/R+21HFdi6tby+pUuDP3SDfmd/LEzs9WvaNOcS4169nP/PKVNsRxQuk24ZEekN4HUAlwLoALAGwDWq+lrQ+ll3yxARNSIb3TJTAbSr6hZVPQpgGYCIHRZERJRUVsl9DADvtQwdbtnvich8EWkTkbY93ksciIgosaySe9A1GGX9P6q6WFVbVbV15MiRGYVBRNQzZZXcOwCM8zwfC2B7RvsiIiKfrJL7GgATRGS8iPQFMBfAioz2RUREPpkMHKaqXSLyNQC/ANAbwBJV3ZDFvoiIqLvMRoVU1Z8D+HlW9RMRUbgecYcqEVFPU4ixZURkD4C3ElQxAsA7KYWTJsYVD+OKr6ixMa54ao3rD1Q18HLDQiT3pESkLewuLZsYVzyMK76ixsa44skiLnbLEBE1ICZ3IqIG1CjJPWDE8kJgXPEwrviKGhvjiif1uBqiz52IiMo1SsudiIg8mNyJiBpQXSf3osz2JCLjRORZEdkoIhtE5Aa3/A4R+Z2IvOz+zLIQ25sist7df5tbNlxEVonIZnc5zEJcZ3uOy8sisl9EbrRxzERkiYjsFpFXPWWhx0hEbnHfc5tEZEbOcX1PRH4rIutE5HERGeqWt4jIEc9x+7es4qoQW+jfzvIx+4knpjdF5GW3PLdjViFHZPc+U9W6/IEzZs0bAM4A0BfAKwAmWoqlGcBk9/EpcGahmgjgDgB/bfk4vQlghK/suwBudh/fDOA7Bfhb7gTwBzaOGYCPAZgM4NVqx8j9u74CoB+A8e57sHeOcX0cwEnu4+944mrxrmfpmAX+7WwfM9/r/wjg/+R9zCrkiMzeZ/Xcci/MbE+qukNVX3QfHwCwEb7JSQpmNoCl7uOlAObYCwUAMA3AG6qa5C7lmqnqrwG86ysOO0azASxT1U5V3QqgHc57MZe4VPVpVe1yn/4GznDauQs5ZmGsHjNDRATApwE8ksW+K6mQIzJ7n9Vzcq8625MNItIC4DwAz7tFX3O/Qi+x0f0BZ5KUp0VkrYjMd8uaVHUH4LzpAIyyEJfXXJT/w9k+ZkD4MSrS++5LAJ7yPB8vIi+JyK9E5CJLMQX97YpyzC4CsEtVN3vKcj9mvhyR2fusnpN71dme8iYigwA8BuBGVd0P4F4AZwL4MIAdcL4S5u2jqjoZwEwAC0TkYxZiCCXOeP9XAHjULSrCMaukEO87EbkVQBeAh92iHQBOV9XzAPwVgP8UkcE5hxX2tyvEMQNwDcobEbkfs4AcEbpqQFmsY1bPyb1Qsz2JSB84f7SHVfW/AEBVd6nqcVU9AeA+ZPRVtBJV3e4udwN43I1hl4g0u3E3A9idd1weMwG8qKq7gGIcM1fYMbL+vhOReQAuB/BZdTto3a/ve93Ha+H00f6vPOOq8LcrwjE7CcAnAfzElOV9zIJyBDJ8n9Vzci/MbE9uX94DADaq6iJPebNntSsBvOrfNuO4ThaRU8xjOCfjXoVznOa5q80D8GSecfmUtaZsHzOPsGO0AsBcEeknIuMBTADwQl5BichlAG4CcIWqHvaUjxSR3u7jM9y4tuQVl7vfsL+d1WPmmg7gt6raYQryPGZhOQJZvs/yOFOc4RnoWXDOOr8B4FaLcVwI5yvTOgAvuz+zADwEYL1bvgJAc85xnQHnjPsrADaYYwTgVACrAWx2l8MtHbeBAPYCGOIpy/2Ywflw2QHgGJwW07WVjhGAW9333CYAM3OOqx1OX6x5n/2bu+5V7t/4FQAvAviEhWMW+rezeczc8n8H8FXfurkdswo5IrP3GYcfICJqQPXcLUNERCGY3ImIGhCTOxFRA2JyJyJqQEzuREQNiMmdiKgBMbkTETWg/w/M3Ap9vbY4fAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# We now start the main function, that means we train the agent...\n",
    "bNotificationStarted = False\n",
    "\n",
    "# Learning factors...\n",
    "EPISODES = 200\n",
    "discount_factor = 0.99\n",
    "learning_rate = 0.001\n",
    "epsilon = 1.0\n",
    "epsilon_decay = 0.999\n",
    "epsilon_min = 0.01\n",
    "batch_size = 64\n",
    "train_start = 1000\n",
    "\n",
    "# empty replay memory using deque\n",
    "memory = deque(maxlen=2000)\n",
    "\n",
    "start = time.time()\n",
    "main()\n",
    "ende = time.time()\n",
    "print(\"\\n\\nLaufzeit: \" + '{:5.3f}s'.format(ende-start))\n",
    "model.save_weights(\"./cartpole_dqn_final.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "5a312273ffa6240539e020f48a5de0b17350fba060a017bafd7c66c880b86767"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
